<!DOCTYPE html>
<html lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/avatar.jpg">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/avatar.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/avatar.jpg">
  <link rel="mask-icon" href="/blog/images/avatar.jpg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/blog/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"beiyuouo.github.io/blog","root":"/blog/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="keywords" content="note,hive">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive笔记">
<meta property="og:url" content="beiyuouo.github.io/blog/note-hive/index.html">
<meta property="og:site_name" content="北屿">
<meta property="og:locale" content="en">
<meta property="og:image" content="/blog/img/note-hive/20200311100017.png">
<meta property="og:image" content="/blog/img/note-hive/20200311102124.png">
<meta property="og:image" content="/blog/img/note-hive/202003121535.png">
<meta property="og:updated_time" content="2021-05-08T16:33:31.651Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive笔记">
<meta name="twitter:image" content="/blog/img/note-hive/20200311100017.png">

<link rel="canonical" href="beiyuouo.github.io/blog/note-hive/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Hive笔记 | 北屿</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-145083103-1"></script>
    <script>
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-145083103-1');
      }
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d396c00ca4fe6547a19249d34cb91254";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">北屿</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">北屿小智障</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/blog/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/blog/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/blog/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-paper-note">

    <a href="/blog/paper-note/" rel="section"><i class="fa fa-fw fa-sticky-note"></i>Paper Note</a>

  </li>
        <li class="menu-item menu-item-thoughts">

    <a href="/blog/categories/thoughts" rel="section"><i class="fa fa-fw fa-quote-left"></i>Thoughts</a>

  </li>
        <li class="menu-item menu-item-academic-page">

    <a href="https://beiyuouo.github.io/" rel="noopener" target="_blank"><i class="fa fa-fw fa-graduation-cap"></i>Academic Page</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/blog/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/beiyuouo" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="beiyuouo.github.io/blog/note-hive/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.jpg">
      <meta itemprop="name" content="BeiYu">
      <meta itemprop="description" content="Sometimes it's the very people who no one imagines angthing of who do the things that no one can imagine.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="北屿">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hive笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-11 09:58:40" itemprop="dateCreated datePublished" datetime="2020-03-11T09:58:40+08:00">2020-03-11</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-05-09 00:33:31" itemprop="dateModified" datetime="2021-05-09T00:33:31+08:00">2021-05-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/blog/categories/note/" itemprop="url" rel="index"><span itemprop="name">note</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/blog/note-hive/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/blog/note-hive/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
            <div class="post-description"><p></p></div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Introduction-to-Hive"><a href="#Introduction-to-Hive" class="headerlink" title="Introduction to Hive"></a>Introduction to Hive</h2><h3 id="Difference-between-SQL-and-NoSQL"><a href="#Difference-between-SQL-and-NoSQL" class="headerlink" title="Difference between SQL and NoSQL"></a>Difference between SQL and NoSQL</h3><p><img src="/blog/img/note-hive/20200311100017.png" alt></p>
<ul>
<li>SQL<br>Relational, Analytical(OLAP)</li>
<li>NoSQL<br>Document, Key-Value, Column-Family, Graph</li>
</ul>
<h3 id="What-is-Hive"><a href="#What-is-Hive" class="headerlink" title="What is Hive"></a>What is Hive</h3><ul>
<li><p>It is an open-source data warehouse system for querying and analyzing large data set stored in HDFS.<br>它是一个开源数据仓库系统，用于查询和分析存储在HDFS中的大数据集。</p>
</li>
<li><p>Its highly scalable.<br>其高度可扩展性。</p>
</li>
<li><p>Hive uses HQL(Hive + SQL) for data summarization, querying and analysis.<br>Hive使用HQL（Hive + SQL）进行数据汇总，查询和分析。</p>
</li>
<li><p>HQL will be converted into map reduce jobs by the Hive component.<br>Hive组件将把HQL转换为map reduce作业</p>
</li>
</ul>
<h3 id="Who-developed-Hive"><a href="#Who-developed-Hive" class="headerlink" title="Who developed Hive"></a>Who developed Hive</h3><ul>
<li><p>Hive was originally developed by Facebook and is now maintained as Apache hive by Apache software foundation.<br>Hive最初由Facebook开发，现在由Apache软件基金会维护为Apache hive。</p>
</li>
<li><p>It is used and developed by biggies such as Netflix and Amazon as well.<br>它也由Netflix和Amazon等大型公司使用和开发</p>
</li>
</ul>
<h3 id="Why-Hive-was-developed"><a href="#Why-Hive-was-developed" class="headerlink" title="Why Hive was developed?"></a>Why Hive was developed?</h3><ul>
<li><p>Traditional organization uses data warehouses that are based on SQL, with users and developers that rely on SQL queries for extracting data.<br>传统组织使用基于SQL的数据仓库，而用户和开发人员则依赖SQL查询来提取数据。</p>
</li>
<li><p>The Hadoop ecosystem is not just scalable but also cost effective when it comes to processing large volumes of data.<br>Hadoop生态系统不仅具有可扩展性，而且在处理大量数据时也具有成本效益。</p>
</li>
<li><p>It makes getting used to the Hadoop ecosystem an uphill task. And that is exactly why hive was developed.<br>这使习惯Hadoop生态系统成为一项艰巨的任务。这就是开发Hive的原因。</p>
</li>
<li><p>Hive provides SQL intellect, so that users can write SQL like queries called HQL or hive query language to extract the data from Hadoop.<br>Hive提供了SQL知识，因此用户可以编写类似HQL的查询之类的SQL或Hive查询语言来从Hadoop提取数据。</p>
</li>
</ul>
<h3 id="How-and-when-it-can-be-used"><a href="#How-and-when-it-can-be-used" class="headerlink" title="How and when it can be used?"></a>How and when it can be used?</h3><ul>
<li><p>Hive can be used for OLAP (online analytic) processing.<br>Hive可用于OLAP（在线分析）处理。</p>
</li>
<li><p>It is scalable, fast and flexible.<br>它具有可扩展性，快速性和灵活性。</p>
</li>
<li><p>It is a great platform for the SQL users to write SQL like queries to interact with the large datasets that reside on HDFS filesystem.<br>对于SQL用户而言，这是一个很棒的平台，可以编写类似于查    询的SQL来与驻留在HDFS文件系统上的大型数据集进行交互</p>
</li>
</ul>
<h3 id="When-Hive-cannot-be-used"><a href="#When-Hive-cannot-be-used" class="headerlink" title="When Hive cannot be used?"></a>When Hive cannot be used?</h3><ul>
<li>It is not a relational database.</li>
<li>It cannot be used fir OLTP(online transaction) processing.</li>
<li>It cannote be used for real time updates or queries.</li>
<li>It cannot be used for scenarios where low latency data retrieval is expected, because there is sa latency in converting the HIVE scripts into MAP REDUCE scripts by Hive.</li>
</ul>
<h3 id="Features-of-Hive"><a href="#Features-of-Hive" class="headerlink" title="Features of Hive"></a>Features of Hive</h3><ul>
<li><p>It supports different file formats like sequence file, text file, avro file format, ORC file, RC file.<br>它支持不同的文件格式，例如序列文件，文本文件，avro文件格式，    ORC文件，RC文件。</p>
</li>
<li><p>Metadata gets stored in RDBMS like derby database.<br>元数据像derby数据库一样存储在RDBMS中。</p>
</li>
<li><p>Hive provides lot of compression techniques, queries on the compressed data such as SNAPPY compression, gzip compression.<br>Hive提供了许多压缩技术，可以对压缩数据进行查询，例如SNAPPY    压缩，gzip压缩。</p>
</li>
<li><p>Users can write SQL like queries that hive converts into mapreduce or tez or spark jobs to query against hadoop datasets.<br>用户可以编写类似查询的SQL，将配置单元转换为mapreduce或tez或    spark作业，以针对hadoop数据集进行查询。</p>
</li>
<li><p>Users can plugin mapreduce scripts into the hive queries using UDF user defined functions.<br>用户可以使用UDF用户定义的函数将mapreduce脚本插入到配置单元    查询中。</p>
</li>
<li><p>Specialized joins are available that help to improve the query performance.<br>可以使用专用联接来帮助提高查询性能</p>
</li>
</ul>
<h3 id="Difference-between-Hive-amp-RDBMS"><a href="#Difference-between-Hive-amp-RDBMS" class="headerlink" title="Difference between Hive &amp; RDBMS"></a>Difference between Hive &amp; RDBMS</h3><p><img src="/blog/img/note-hive/20200311102124.png" alt></p>
<h2 id="Hive-Chapter-1"><a href="#Hive-Chapter-1" class="headerlink" title="Hive Chapter 1"></a>Hive Chapter 1</h2><h3 id="What-is-Hive-1"><a href="#What-is-Hive-1" class="headerlink" title="What is Hive?"></a>What is Hive?</h3><ul>
<li>HIVE is a data warehouse architecture built on the Hadoop file system.<br>HIVE是一个建立在Hadoop文件系统上的数据仓库架构。</li>
<li>HIVE analyzes and manages the data stored in HDFS.<br>HIVE分析和管理存储在HDFS中的数据。                </li>
<li>It mainly provides the following functions:主要提供以下功能:<br>Provides a series of tools for extracting / transforming / loading data (ETL)<br>提供了一系列用于提取/转换/加载数据(ETL)的工具</li>
<li>Is a mechanism that can store, query, and analyze large-scale data stored in HDFS (or HBase)<br>是一种可以存储、查询和分析储存于HDFS(或HBase)中的大规模数据的机制</li>
<li>The query is done through MapReduce (not all queries require MapReduce to complete, such as <code>select * from XXX</code> is not required;<br>查询是通过MapReduce完成的(并不是所有的查询都需要MapReduce来完成，例如从XXX中选择<code>select *</code>是不需要的);</li>
<li>In Hive, queries like <code>select a, b from XXX</code> can be configured without MapReduce through configuration.<br>在Hive中，像从XXX中选择<code>a, b</code>这样的查询可以在没有MapReduce的情况下通过配置进行配置。</li>
</ul>
<h3 id="How-to-analyze-and-manage-data-如何分析和管理数据"><a href="#How-to-analyze-and-manage-data-如何分析和管理数据" class="headerlink" title="How to analyze and manage data? 如何分析和管理数据?"></a>How to analyze and manage data? 如何分析和管理数据?</h3><ul>
<li>Hive defines a SQL-like query language called HQL.<br>Hive定义了一种类似SQL的查询语言，称为HQL。</li>
<li>Hive can be used to query data directly.<br>Hive可以用于直接查询数据。</li>
<li>At the same time, the language also allows developers to develop custom mappers and reducers to handle complex analysis tasks that the built-in mappers and reducers cannot complete.<br>与此同时，该语言还允许开发人员开发定制的Mappers和Reducers来处理内置的Mappers和Reducers无法完成的复杂分析任务。</li>
<li>Hive allows users to write their own function UDFs.<br>Hive允许用户编写自己的函数UDFs。</li>
<li>There are three types of UDFs in Hive: 在Hive中有三种类型的UDFs:<ul>
<li>User Defined Functions (UDF) 用户定义函数(UDF)</li>
<li>User Defined Aggregation Functions (UDAF) 用户定义聚合函数(UDAF)</li>
<li>User Defined Table Generating Functions (UDTF). 用户定义的表生成函数(UDTF)</li>
</ul>
</li>
<li>Hive parses external tasks into a MapReduce executable plan. MapReduce is a high-latency event.<br>Hive将外部任务解析为MapReduce可执行计划。MapReduce是一个高延迟的事件。</li>
<li>Each submission and execution of a task takes a lot of time, which determines that Hive can only handle some high-latency application.<br>任务的每次提交和执行都需要大量的时间，这决定了Hive只能处理一些高延迟的应用程序</li>
<li>Hive currently has the following disadvantages： 目前Hive有以下缺点:<ul>
<li>Hive does not  support transactions; Hive不支持交易;</li>
<li>Table data cannot be modified 无法修改表数据</li>
<li>Columns cannot be indexed 列不能被索引</li>
</ul>
</li>
</ul>
<h3 id="HIVE-Data-Storage-Model-HIVE数据存储模型"><a href="#HIVE-Data-Storage-Model-HIVE数据存储模型" class="headerlink" title="HIVE Data Storage Model.  HIVE数据存储模型"></a>HIVE Data Storage Model.  HIVE数据存储模型</h3><p>HIVE data is divided into :   Hive数据分为：</p>
<ul>
<li>Table data : Table data is the data that tables in Hive have<br>表数据: 表数据是Hive中的表所拥有的数据</li>
<li>Metadata : Metadata is used to store the data about the table.<br>元数据: 元数据用于存储关于表的数据。</li>
</ul>
<h3 id="HIVE-Data-Storage-Hive数据存储"><a href="#HIVE-Data-Storage-Hive数据存储" class="headerlink" title="HIVE Data Storage. Hive数据存储"></a>HIVE Data Storage. Hive数据存储</h3><ul>
<li>Hive is based on the Hadoop distributed file system.<br>Hive是基于Hadoop分布式的文件系统</li>
<li>HIVE data is stored in the Hadoop distributed file system.<br>Hive数据存储在Hadoop分布式文件系统中</li>
<li>We  only need to specify  the column and row separators in the data when we  create the table.<br>我们只需要在创建表时指定数据中的列和行分隔符。</li>
<li>Hive can parse the data.<br>Hive可以解析数据。</li>
<li>Importing  HDFS data into a Hive table is simply moving the data to the directory where the table is located.<br>将HDFS数据导入到Hive表中只是将数据移动到表所在的目录中。</li>
<li>The data in the local file system, need to copy in the same directory of the table.<br>数据在本地文件系统中，需要复制在相同目录下的表。</li>
</ul>
<h3 id="Hive-Data-Models-Table-Hive-数据模型-Table"><a href="#Hive-Data-Models-Table-Hive-数据模型-Table" class="headerlink" title="Hive Data Models-Table. Hive 数据模型-Table"></a>Hive Data Models-Table. Hive 数据模型-Table</h3><ul>
<li>Tables in Hive are similar in concept to tables in relational databases.<br>Hive中的表在概念上与关系数据库中的表相似。</li>
<li>Each table has a corresponding directory in HDFS to store the table’s data.<br>每个表在HDFS中都有一个对应的目录来存储表的数据。</li>
<li>This directory can be accessed through <code>$ {HIVE_HOME} / conf / hive-site</code>.<br>可以通过<code>$ {HIVE_HOME} / conf / hive-site</code> 访问这个目录。</li>
<li>The <code>hive.metastore.warehouse.dir</code> property in the xml configuration file is used to configure.<br><code>hive.metastore.warehouse.dir</code> 属性在xml配置文件中进行配置。</li>
<li>The default value of this property is <code>/ user / hive / warehouse</code> (this directory is on HDFS).         此属性的默认值是<code>/ user / hive / warehouse</code>(此目录位于HDFS上)。</li>
<li>We can modify this configuration according to requirement.<br>我们可以根据需要修改这个配置。</li>
</ul>
<h3 id="Hive-Data-Models-External-Table-Hive-数据模型"><a href="#Hive-Data-Models-External-Table-Hive-数据模型" class="headerlink" title="Hive Data Models-External Table. Hive 数据模型"></a>Hive Data Models-External Table. Hive 数据模型</h3><ul>
<li>The external table in HIVE is very similar to the table, but its data is not stored in the directory to which the table belongs but stored elsewhere.<br>HIVE中的external table(外部表)与该表非常相似，但是它的数据不是存储在该表所属的目录中，而是存储在其他地方。</li>
<li>If we delete the data of external table, the data pointed to by the external table is not  deleted, it deletes the metadata corresponding to the external table<br>如果我们删除了外部表的数据，external table(外部表)指向的数据并没有被删除，它删除了与external table(外部表)对应的元数据</li>
<li>If we want to delete the table, all the data corresponding to the table including the metadata will be deleted.<br>如果要删除该表，则删除该表所对应的所有数据，包括元数据。</li>
</ul>
<h3 id="Hive-Data-Models-Partition-Hive-数据模型-Partition"><a href="#Hive-Data-Models-Partition-Hive-数据模型-Partition" class="headerlink" title="Hive Data Models-Partition. Hive 数据模型-Partition"></a>Hive Data Models-Partition. Hive 数据模型-Partition</h3><ul>
<li>In Hive, each partition of the table corresponds to the respective  directory under the table, and the data of all partitions is stored in the corresponding directory.<br>在Hive中，表的每个分区对应于表下的各个目录，所有partitions(分区)的数据都    存储在相应的目录中。</li>
</ul>
<h3 id="Hive-Data-Models-Bucket-Hive-数据模型-Bucket"><a href="#Hive-Data-Models-Bucket-Hive-数据模型-Bucket" class="headerlink" title="Hive Data Models-Bucket. Hive 数据模型-Bucket"></a>Hive Data Models-Bucket. Hive 数据模型-Bucket</h3><ul>
<li>Calculate the hash of the specified column and slice the data according to the hash value.<br>指定列计算 hash，并根据 hash 值切分数据。</li>
<li>The purpose is to parallelize each bucket corresponding to a file<br>其目的是将每个Bucket(桶)对应于一个文件并行化</li>
</ul>
<h3 id="Hive-MetaData"><a href="#Hive-MetaData" class="headerlink" title="Hive MetaData"></a>Hive MetaData</h3><ul>
<li>The metadata in Hive includes the name of the table, the columns and partitions of the table and their attributes<br>Hive中的元数据包括表的名称、列和表的partitions(分区)以及它们的属性</li>
<li>HIVE metadata needs to be constantly updated and modified.<br>HIVE元数据需要不断更新和修改。</li>
<li>Files in the HDFS system are available for read operation more and does not support frequent  modification, hence we  cannot store Hive’s metadata in HDFS.<br>HDFS系统中的文件可用于更多的读取操作，不支持频繁的修改，因此我们不能将Hive的元数据存储在HDFS中。</li>
<li>Currently Hive stores metadata in databases, such as Mysql and Derby.<br>目前Hive将元数据存储在数据库中，如MySQL和Derby。</li>
</ul>
<h3 id="Hive-Storage-model"><a href="#Hive-Storage-model" class="headerlink" title="Hive Storage model"></a>Hive Storage model</h3><p><img src="/blog/img/note-hive/202003121535.png" alt></p>
<h3 id="Database-Model"><a href="#Database-Model" class="headerlink" title="Database Model"></a>Database Model</h3><p>The ACID acronym stands for:</p>
<ul>
<li>Atomic<br>All operations in a transaction succeed or every operation is rolled back.</li>
<li>Consistent<br>On the completion of a transaction, the database is structurally sound.</li>
<li>Isolated<br>Transactions do not contend with one another. Contentious access to data is moderated by the database so that transactions appear to run sequentially.</li>
<li>Durable<br>The results of applying a transaction are permanent, even in the presence of failures.</li>
</ul>
<p>ACID properties mean that once a transaction is complete, its data is consistent (tech lingo: write consistency) and stable on disk, which may involve multiple distinct memory locations.</p>
<p>Write consistency is a wonderful thing for application developers, but it also requires sophisticated locking which is typically a heavyweight pattern for most use cases.<br>When it comes to NoSQL technologies, most graph databases(including Neo4j) use an ACID consistency model to ensure data is safe and consistently stored.</p>
<p>Here’s how the BASE acronym breaks down:</p>
<ul>
<li>Basic Availability<br>The database appears to work most of the time.</li>
<li>Soft-state<br>Stores don’t have to be write-consistent, nor do different replicas have to be mutually consistent all the time.</li>
<li>Eventual consistency</li>
</ul>
<p>Stores exhibit consistency at some later point (e.g., lazily at read time).<br>BASE properties are much looser than ACID guarantees, but there isn’t a direct one-for-one mapping between the two consistency models (a point that probably can’t be overstated).</p>
<p>A BASE data store values availability (since that’s important for scale), but it doesn’t offer guaranteed consistency of replicated data at write time. Overall, the BASE consistency model provides a less strict assurance than ACID: data will be consistent in the future, either at read time (e.g., Riak) or it will always be consistent, but only for certain processed past snapshots (e.g., Datomic).</p>
<p>The BASE consistency model is primarily used by aggregate stores, including column family, key-value and document stores.</p>
<h3 id="Hive-Installation"><a href="#Hive-Installation" class="headerlink" title="Hive Installation"></a>Hive Installation</h3><h4 id="基于Derby"><a href="#基于Derby" class="headerlink" title="基于Derby"></a>基于Derby</h4><ol>
<li>下载<br><a href="https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-1.2.2/" target="_blank" rel="noopener">https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-1.2.2/</a></li>
<li>将文件传到Linux <code>/home/hadoop/Download</code></li>
<li>解压<br>到<code>~/Download</code>目录下找到文件，<code>tar -zvxf apache-hive-1.2.2-bin.tar.gz -C ~/app/</code></li>
<li><code>vi ~/.bash_profile</code>在最后添加两行<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HIVE_HOME=/home/hadoop/app/apache-hive-1.2.2-bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>最后<code>source ~/.bash_profile</code></p>
<ol>
<li>输入<code>hive --version</code>查看是否安装成功</li>
<li><p>开启hadoop <code>start-all.sh</code><br>运行下面的</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir -p /user/hive/warehouse</span><br><span class="line">hdfs dfs -mkdir  /user/hive/tmp</span><br><span class="line">hdfs dfs -mkdir  /user/hive/<span class="built_in">log</span></span><br><span class="line">hdfs dfs -chmod g+w /user/hive/warehouse</span><br><span class="line">hdfs dfs -chmod g+w /user/hive/tmp</span><br><span class="line">hdfs dfs -chmod g+w /user/hive/<span class="built_in">log</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>然后去<code>/home/hadoop/app/apache-hive-1.2.2-bin/conf</code>copy一下模板修改<code>hive-site.xml</code>和<code>hive-env.sh</code></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp hive-env.sh.template hive-env.sh</span><br><span class="line">cp hive-default.xml.template hive-default.xml</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>在<code>hive-env.sh</code>中添加<code>vi hive-env.sh</code><br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_HOME=/home/hadoop/app/hadoop-2.7.3</span><br><span class="line"><span class="built_in">export</span> HIVE_CONF_DIR=/home/hadoop/app/apache-hive-1.2.2-bin/conf</span><br><span class="line"><span class="built_in">export</span> HIVE_AUX_JARS_PATH=/home/hadoop/app/apache-hive-1.2.2-bin/lib</span><br></pre></td></tr></table></figure></p>
<p>新建<code>hive-site.xml</code>添加<code>vi hive-site.xml</code><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/log<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:derby:;databaseName=/home/hadoop/app/apache-hive-1.2.2-bin/metastore_db;create=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.derby.jdbc.EmbeddedDriver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.PersistenceManagerFactoryClass<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.datanucleus.api.jdo.JDOPersistenceManagerFactory<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>system:java.io.tmpdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<ol>
<li><p>初始化数据库<br><code>schematool -initSchema -dbType derby</code></p>
</li>
<li><p>加权限</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo chgrp -R hadoop /user/hive/</span><br><span class="line">sudo chown -R hadoop /user/hive/</span><br></pre></td></tr></table></figure>
</li>
<li><p>开启hive <code>hive</code></p>
</li>
</ol>
<h4 id="基于Mysql"><a href="#基于Mysql" class="headerlink" title="基于Mysql"></a>基于Mysql</h4><ol>
<li><p>jar包<br>mpsql - JDBC <a href="https://dev.mysql.com/downloads/connector/j/" target="_blank" rel="noopener">https://dev.mysql.com/downloads/connector/j/</a><br>这个jar包放在<code>${HIVE_HOME}/lib</code>中，</p>
</li>
<li><p><code>hive-site.xml</code>配置文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://192.168.0.104:3306/hive?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 这里填自己的地址，URL里添加创建数据库好像我的不行 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span> <span class="comment">&lt;!-- 用户名 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span> <span class="comment">&lt;!-- 密码 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive1234<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>system:java.io.tmpdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.exec.scratdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.querylog.location<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/log<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>mysql添加用户</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> <span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> hive;</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">USER</span> <span class="string">'hive'</span> <span class="keyword">IDENTIFIED</span> <span class="keyword">BY</span> <span class="string">'hive1234'</span>;</span><br><span class="line"><span class="keyword">GRANT</span> ALL <span class="keyword">PRIVILEGES</span> <span class="keyword">ON</span> *.* <span class="keyword">TO</span> <span class="string">'hive'</span>@<span class="string">'%'</span> <span class="keyword">WITH</span> <span class="keyword">GRANT</span> <span class="keyword">OPTION</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化数据库<br><code>schematool -initSchema -dbType mysql</code></p>
</li>
<li><p>启动hive <code>hive</code></p>
</li>
</ol>
<h3 id="CLI-Options"><a href="#CLI-Options" class="headerlink" title="CLI Options"></a>CLI Options</h3><p>The Hive command line interface (CLI) is used to interact with Hive. Users can use CLI commands to create, manage, and query tables.<br>Hive命令行接口(CLI)用于与Hive交互。用户可以使用CLI命令来创建、管理和查询表。<br>You can view the related instructions of Hive through the help command of Hive.<br>你可以通过Hive的help命令查看Hive的相关指令。 <code>hive --help --service cli</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Usage</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>-d,--define &lt;key=value&gt;</code></td>
<td style="text-align:center">Variable subsitution to apply to hive commands. e.g. <code>hive -d A=B</code></td>
</tr>
<tr>
<td style="text-align:center"><code>--database &lt;databasename&gt;</code></td>
<td style="text-align:center">Specify the database to use</td>
</tr>
<tr>
<td style="text-align:center"><code>-e &lt;quoted-query-string&gt;</code></td>
<td style="text-align:center">SQL from command line</td>
</tr>
<tr>
<td style="text-align:center"><code>-f &lt;filename&gt;</code></td>
<td style="text-align:center">SQL from file</td>
</tr>
<tr>
<td style="text-align:center"><code>-H, --help</code></td>
<td style="text-align:center">Print help information</td>
</tr>
<tr>
<td style="text-align:center"><code>--hiveconf &lt;property=value&gt;</code></td>
<td style="text-align:center">Use value for give property</td>
</tr>
<tr>
<td style="text-align:center"><code>--hivevar &lt;key=value&gt;</code></td>
<td style="text-align:center">Varibale subsitution to apply to hive commands.</td>
</tr>
<tr>
<td style="text-align:center"><code>-i &lt;filename&gt;</code></td>
<td style="text-align:center">Initialization SQL file</td>
</tr>
<tr>
<td style="text-align:center"><code>-S, --silent</code></td>
<td style="text-align:center">Silent mode in interactive shell</td>
</tr>
<tr>
<td style="text-align:center"><code>-v,--verbose</code></td>
<td style="text-align:center">Verbose mode (echo executed SQL to the console)</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Variable-setting"><a href="#Variable-setting" class="headerlink" title="Variable setting"></a>Variable setting</h3><p>Hive variables are preceded by a namespace, including 4 hiveconf, system, env, and hivevar.<br>Hive变量前有一个名称空间，包括这4个:  hiveconf、system、env和hivevar。</p>
<ul>
<li>hiveconf: refers to the value of configuration variables under hive-site.xml.<br>hiveconf: 指的是hive-site.xml下的配置变量的值。</li>
<li>system: is a system variable, including the running environment of the JVM.<br>system: 是一个系统变量，包括JVM的运行环境。</li>
<li>env: refers to environment variables, including variable information in the Shell environment, such as HADOOP_HOME.<br>env: 指的是环境变量，包括Shell环境中的变量信息，如HADOOP_HOME。</li>
<li><p>hivevar: user-defined variable.<br>hivevar: 用户定义的变量。</p>
</li>
<li><p>Ordinary variables can be declared with <code>--define key = value</code> or <code>--hivevar key = value</code>, which all represent variables that are hivevar.<br>普通变量可以用<code>-- define key = value</code> 或 <code>-- hivevar key = value</code> 声明，它们都表示变量是hivevar。</p>
</li>
<li><code>hive --hiveconf mapreduce.job.queuename=queue1</code><br>This setting is valid for the session started this time and needs to be reconfigured for the next startup.<br>此设置对这次启动的会话有效，下一次启动需要重新配置。</li>
<li>Set or display variables through set in hive.<br>通过在Hive中设置或显示变量。<code>set &lt;varname&gt;</code></li>
</ul>
<h3 id="Hive-Command-line"><a href="#Hive-Command-line" class="headerlink" title="Hive Command line"></a>Hive Command line</h3><ul>
<li>One-time query 一次性查询<br><code>$HIVE_HOME/bin/hive -e &#39;select a.col from tab1 a&#39;</code><br>The progress of mapreduce will be displayed on the terminal. Mapreduce的进度将显示在终端上。<br>The query results are finally output to the terminal, and hive process exits 查询结果最终输出到终端，Hive进程退出</li>
<li>Quiet mode query 安静模式查询<br><code>$HIVE_HOME/bin/hive  -S -e &#39;select a.ueserid from tab1 log&#39;</code><br>Adding  <code>-S</code>, will only output the query results to the terminal. 添加 <code>–S</code>，仅将查询结果输出到终端。<br>This silent mode is called by a third-party program, the third-party program obtains the result set through the standard output of hive. 这种静音模式是由第三方程序调用的，第三方程序通过Hive的标准输出获取结果集。</li>
<li>Execute script 执行脚本<br><code>$HIVE_HOME/bin/hive -f /home/my/hive-script.sql</code><br><code>hive-script.sql</code> is a script file written using hive sql syntax. The execution process is similar to <code>-e</code>, except that sql is loaded from a file.<br><code>hive-script.sql</code>是一个使用Hive SQL语法编写的脚本文件。执行过程类似于<code>-e</code>，只是SQL是从一个文件加载的。</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Command</th>
<th style="text-align:center">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><code>quit/exit</code></td>
<td style="text-align:center">Exit the interactive shell</td>
</tr>
<tr>
<td style="text-align:center"><code>Reset</code></td>
<td style="text-align:center">Reset configuration to default</td>
</tr>
<tr>
<td style="text-align:center"><code>set &lt;key&gt;=&lt;value&gt;</code></td>
<td style="text-align:center">Modify the value of a specific variableNote: If the variable name is misspelled, no error will be reported</td>
</tr>
<tr>
<td style="text-align:center"><code>Set</code></td>
<td style="text-align:center">Output user-overwritten hive configuration variables</td>
</tr>
<tr>
<td style="text-align:center"><code>set -v</code></td>
<td style="text-align:center">Output all Hadoop and Hive configuration variables</td>
</tr>
<tr>
<td style="text-align:center"><code>add FILE[S] &lt;filepath&gt; &lt;filepath&gt;*</code> <br> <code>add JAR[S] &lt;filepath&gt; &lt;filepath&gt;*</code> <br> <code>add ARCHIVE[S] &lt;filepath&gt; &lt;filepath&gt;*</code></td>
<td style="text-align:center">Add one or more files, jars, archives to the distributed cache</td>
</tr>
<tr>
<td style="text-align:center"><code>list FILE[S]</code> <br> <code>list JAR[S]</code> <br> <code>list ARCHIVE[S]</code></td>
<td style="text-align:center">Outputs resources that have been added to the distributed cache.</td>
</tr>
<tr>
<td style="text-align:center"><code>list FILE[S] &lt;filepath&gt;*</code> <br> <code>list JAR[S] &lt;filepath&gt;*</code> <br> <code>list ARCHIVE[S] &lt;filepath&gt;*</code></td>
<td style="text-align:center">Check if given resource is added to distributed cache</td>
</tr>
<tr>
<td style="text-align:center"><code>delete FILE[S] &lt;filepath&gt;*</code> <br> <code>delete JAR[S] &lt;filepath&gt;*</code> <br> <code>delete ARCHIVE[S] &lt;filepath&gt;*</code></td>
<td style="text-align:center">Deletes the specified resource from the distributed cache</td>
</tr>
<tr>
<td style="text-align:center"><code>! &lt;command&gt;</code></td>
<td style="text-align:center">Execute a shell command from the Hive shell</td>
</tr>
<tr>
<td style="text-align:center"><code>dfs &lt;dfs command&gt;</code></td>
<td style="text-align:center">Execute a dfs command from the Hive shell</td>
</tr>
<tr>
<td style="text-align:center"><code>&lt;query string&gt;</code></td>
<td style="text-align:center">Execute a Hive query and output the results to standard output</td>
</tr>
<tr>
<td style="text-align:center"><code>source FILE &lt;filepath&gt;</code></td>
<td style="text-align:center">Execute a hive script file in the CLI</td>
</tr>
</tbody>
</table>
</div>
<h3 id="HIVE-Data-Type"><a href="#HIVE-Data-Type" class="headerlink" title="HIVE Data Type"></a>HIVE Data Type</h3><p>Primary data types<br>TINYINT, SMALLINT, INT, BIGINT, FLOAT, DOUBLE, BOOLEAN, STRING<br>Complex Data Types</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Type</th>
<th style="text-align:center">Description</th>
<th style="text-align:center">Example</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ARRAY</td>
<td style="text-align:center">A set of ordered fields. Field must be of same type.</td>
<td style="text-align:center"><code>Array(1, 2)</code></td>
</tr>
<tr>
<td style="text-align:center">MAP</td>
<td style="text-align:center">An unordered set of key/value pairs. The key type must be atomic, the value can be any type. The key type of the same mapping must be the same, and the value type must be the same.</td>
<td style="text-align:center"><code>Map(&#39;a&#39;, 1, &#39;b&#39;, 2)</code></td>
</tr>
<tr>
<td style="text-align:center">STRUCT</td>
<td style="text-align:center">A set of named fields. The field type can be different.</td>
<td style="text-align:center"><code>Struct(&#39;a&#39;,1,1,0)</code></td>
</tr>
</tbody>
</table>
</div>
<h2 id="Chapter-2"><a href="#Chapter-2" class="headerlink" title="Chapter 2"></a>Chapter 2</h2><h3 id="Database-Operations"><a href="#Database-Operations" class="headerlink" title="Database Operations"></a>Database Operations</h3><ul>
<li>SHOW DATABASE: <code>show databases;</code></li>
<li><p>CREATE DATABASE: </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Create</span> [<span class="keyword">EXTERNAL</span>] <span class="keyword">TABLE</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] table_name </span><br><span class="line">[(col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)] </span><br><span class="line">[<span class="keyword">COMMENT</span> table_comment] </span><br><span class="line">[PARTITIONED <span class="keyword">BY</span> (col_name data_type [<span class="keyword">COMMENT</span> col_comment], ...)] </span><br><span class="line">[CLUSTERED <span class="keyword">BY</span> (col_name, col_name, ...) </span><br><span class="line">[SORTED <span class="keyword">BY</span> (col_name [<span class="keyword">ASC</span>|<span class="keyword">DESC</span>], ...)] <span class="keyword">INTO</span> num_buckets BUCKETS] </span><br><span class="line">[<span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> row_format] </span><br><span class="line">[<span class="keyword">STORED</span> <span class="keyword">AS</span> file_format] </span><br><span class="line">[LOCATION hdfs_path]</span><br></pre></td></tr></table></figure>
</li>
<li><p>USE DATABASE: <code>use database;</code></p>
</li>
<li>DELETE DATABASE: <code>DROP DATABASE [IF EXISTS] &lt;database name&gt;</code></li>
</ul>
<h3 id="Table-Operations"><a href="#Table-Operations" class="headerlink" title="Table Operations"></a>Table Operations</h3><ul>
<li><p>CREATE TABLE  :<br>Creates a table with the specified name.<br>If a table with the same name already exists, an exception is thrown;<br>The user can use the IF NOT EXIST option to ignore this exception. </p>
</li>
<li><p>EXTERNAL :<br>External  keyword allows users to create an external table, and specify a path to the actual data (LOCATION).<br>When you delete external table only deletes the metadata, not the data.</p>
</li>
<li><p>ROW FORMAT DELIMITED] :<br>[ROW FORMAT DELIMITED]keyword is used to set the column separators supported by the created table when loading data.</p>
</li>
<li>[STORED AS file_format] :<br>specifies the file storage format. The default is TEXTFILE. If the file data is plain text, [STORED AS TEXTFILE] is used and then copied directly to HDFS from the local.</li>
<li>Partitioned tables can be created using the PARTITIONED BY statement. A table can have one or more partitions, and each partition exists in a separate directory. </li>
<li>Both tables and partitions can perform a CLUSTERED BY operation on a certain column and put several columns into a bucket. You can also use SORT BY to sort the data. This can improve performance for specific applications.</li>
</ul>
<h4 id="File-formats"><a href="#File-formats" class="headerlink" title="File formats"></a>File formats</h4><ul>
<li><p>TEXTFILE:<br>The TEXTFILE is default format. Data is not compressed. It has a large disk overhead and a large data parsing overhead.</p>
</li>
<li><p>SEQUENCEFILE:<br>SEQUENCEFILE a binary file support provided by the Hadoop API, which is easy to use, splittable and compressible.</p>
</li>
<li><p>RCFILE:<br>RCFILE is a combination of row and column storage.</p>
</li>
<li><p>Custom format: </p>
<ul>
<li>When the user’s data file format cannot be recognized by the current Hive, you can customize the file format.</li>
<li>Users can customize input and output formats by implementing inputformat and outputformat.</li>
</ul>
</li>
</ul>
<h4 id="CREATE-TABLE"><a href="#CREATE-TABLE" class="headerlink" title="CREATE TABLE"></a>CREATE TABLE</h4><ul>
<li>Create a normal table：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> Emp_table (<span class="keyword">id</span> <span class="built_in">int</span>,<span class="keyword">name</span> <span class="keyword">string</span>,<span class="keyword">no</span> <span class="built_in">int</span>) </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">',’ stored as textfile;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Note : A field separator is specified. HIVE only supports a single character separator. The default delimiter for hive is \ 001.</p>
<ul>
<li>Create a partitioned table<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> Emp_partition (<span class="keyword">id</span> <span class="built_in">int</span>,<span class="keyword">name</span> <span class="keyword">string</span>,<span class="keyword">no</span> <span class="built_in">int</span>) partitioned <span class="keyword">by</span> (dt <span class="keyword">string</span>) </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">',’  stored as textfile ;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>load data local inpath <code>&#39;/opt/niit/hive/test_hive.txt&#39;</code> overwrite into table test_partition partition (dt=’2015-06-15’);</p>
<ul>
<li><p>Create a bucket table</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> Emp_bucket (<span class="keyword">id</span> <span class="built_in">int</span>,<span class="keyword">name</span> <span class="keyword">string</span>,<span class="keyword">no</span> <span class="built_in">int</span>) partitioned <span class="keyword">by</span> (dt <span class="keyword">string</span>) </span><br><span class="line">clustered <span class="keyword">by</span> (<span class="keyword">id</span>) sorted <span class="keyword">by</span>(<span class="keyword">name</span>) <span class="keyword">into</span> <span class="number">3</span> buckets </span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line"><span class="keyword">stored</span> <span class="keyword">as</span> textfile;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Create an external table</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> Emp_external (<span class="keyword">id</span> <span class="built_in">int</span>,<span class="keyword">name</span> <span class="keyword">string</span>,<span class="keyword">no</span> <span class="built_in">int</span>)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span> <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">',’ ;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Copy table structure</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> Emp_like_table <span class="keyword">like</span> Emp_bucket;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>The above command copies table structure only, not content</p>
<h3 id="Modify-Table-Operations"><a href="#Modify-Table-Operations" class="headerlink" title="Modify Table Operations"></a>Modify Table Operations</h3><ul>
<li><p>Increase partition<br>Syntax：<code>ALTER TABLE table_name ADD partition_spec [ LOCATION &#39;location1&#39;] partition_spec [ LOCATION &#39;location2&#39; ]</code><br>Example：<code>alter table Emp_partition add partition (dt=&#39;2015-06-15&#39;)</code></p>
</li>
<li><p>Delete partition<br>Syntax：<code>ALTER TABLE table_name DROP partition_spec</code><br>Example：<code>alter table Emp_partition drop partition (dt=&#39;2015-06-15&#39;)</code><br>Description：After the partition is deleted, the metadata and data of the partition will be deleted together.</p>
</li>
</ul>
<h3 id="Table-Operations-1"><a href="#Table-Operations-1" class="headerlink" title="Table Operations"></a>Table Operations</h3><ul>
<li><p>Table rename<br>Syntax：<code>ALTER TABLE table_name RENAME TO new_table_name</code><br>Example：<code>alter table Emp_partition rename to new_Emp_partition;</code><br>Description：The location of the data and the partition name do not change.</p>
</li>
<li><p>Modify table column type<br>Syntax：<code>ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name column_type [COMMENT col_comment] [FIRST|AFTER column_name]</code><br>Example：<code>alter table New_Emp_partition change name name1 String;</code></p>
</li>
<li><p>Add column<br>Syntax：<code>ALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT col_comment], ...)</code><br>Example：<code>alter table New_Emp_partition  add columns (age int);</code></p>
</li>
</ul>
<h3 id="Data-loading"><a href="#Data-loading" class="headerlink" title="Data loading"></a>Data loading</h3><ul>
<li>Hive does not support insert operations using insert statements one by one. It also  does not  support update operations.<br>Hive不支持使用一个接一个的插入语句进行插入操作。它也不支持更新操作。</li>
<li>The data is loaded into the established table in the manner of load.<br>数据以加载的方式加载到已建立的表中。</li>
<li>Once the data is imported, it cannot be modified.  We can either drop the entire table or create a new table and import the required data.<br>一旦数据被导入，它就不能被修改。 我们可以删除整个表，也可以创建一个新表并导入所需的数据。</li>
</ul>
<p>Syntax：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LOAD</span> <span class="keyword">DATA</span> [<span class="keyword">LOCAL</span>] INPATH <span class="string">'filepath'</span> [OVERWRITE] <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)]</span><br></pre></td></tr></table></figure></p>
<h3 id="Ways-to-Import-data-in-batches"><a href="#Ways-to-Import-data-in-batches" class="headerlink" title="Ways to Import data in batches"></a>Ways to Import data in batches</h3><ul>
<li>Load data and import to the specified table    加载数据并导入到指定的表<br>Import the local file system /home/data/aa.txt file into tab1,<br>syntax : <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/home/data/aa.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> tab1;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Import the file directly to the partition of the specified table. If the partition directory does not exist, hive will automatically create a partition directory, and then copy the data to the directory.<br>将文件直接导入指定表的分区。如果分区目录不存在，HIVE将自动创建一个分区目录，然后将数据复制到该目录。</p>
<ul>
<li>Load to the partition of the specified table    加载到指定表的分区<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA LOCAL INPATH &apos;/home/admin/test/test.txt’</span><br><span class="line">OVERWRITE INTO TABLE test_1 PARTITION（pt=’xxxx’）</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>The keyword [OVERWRITE] means to overwrite the data in the original table. If it is not written, it will not be overwritten.<br>关键字[OVERWRITE]表示覆盖原始表中的数据。如果不写，就不会被覆盖。<br>The keyword [LOCAL] means that the source of the file you are loading is a local file. If you do not write, the file is hdfs.<br>关键字[LOCAL]表示正在加载的文件的源是一个本地文件。如果不写，文件是HDFS。</p>
<ul>
<li>Import data using insert + select<br>By querying the table, the query results are imported into the specified table.    通过查询表，查询结果被导入到指定的表中。<br>Syntax ：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)] select_statement1 <span class="keyword">FROM</span> from_statement</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">into</span> tab2 <span class="keyword">select</span> * <span class="keyword">from</span> tab1；</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Import data using create+select<br>Create a new table and copy the data into this table.<br>创建一个新表并将数据复制到这个表中。<br>Syntax：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tablename1 <span class="keyword">AS</span>  select_statement1 <span class="keyword">FROM</span> from_statement  </span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">table</span> tab2 <span class="keyword">as</span> <span class="keyword">select</span> * <span class="keyword">from</span> tab1;</span><br></pre></td></tr></table></figure></p>
<h3 id="Management-tables"><a href="#Management-tables" class="headerlink" title="Management tables"></a>Management tables</h3><ul>
<li>The management table is also called an internal table.<br>管理表也称为内部表。</li>
<li>Hive controls the life cycle of the table and the data in the table.<br>Hive控制表的生命周期和表中的数据。</li>
<li>The data is stored in the directory set by the parameter hive.metastore.warehouse.dir in hive-site.xml.<br>数据存储在参数设置的目录中：</li>
<li>When Hive creates the internal tables, it moves the data to the path pointed to by the data warehouse.<br>当Hive创建内部表时，它将数据移动到数据仓库指向的路径。</li>
<li>When a management table is deleted, the corresponding data in the table is also deleted at the same time.<br>删除管理表时，同时也删除表中相应的数据。</li>
<li>We can create a management table by using the <code>create table</code> command.<br>我们可以使用create table命令来创建一个管理表。</li>
</ul>
<h3 id="External-tables"><a href="#External-tables" class="headerlink" title="External tables"></a>External tables</h3><ul>
<li>The data of the external table is not managed by hive, hive just establishes a reference.<br>外部表的数据不是由hive管理的，hive只是建立一个引用。</li>
<li>When deleting an external table, only the metadata of the table is deleted, not the data.<br>删除外部表时，只删除表的元数据，而不删除数据。</li>
<li>The external table is relatively more secure, and the data organization is more flexible, which facilitates the sharing of source data.<br>外部表相对更安全，数据组织也更灵活，这有助于共享源数据。</li>
<li>Create table Use “create EXTERNAL table” to create external tables.<br>创建表使用创建外部表来创建外部表。</li>
</ul>
<h3 id="Partition-Table"><a href="#Partition-Table" class="headerlink" title="Partition Table"></a>Partition Table</h3><ul>
<li>Hive Select query scan  the entire table  which  is time consuming.<br>在HIVE选择查询扫描整个表，这是耗时的。</li>
<li>Sometimes only a part of the data in the table needs to be scanned, so the partition concept was introduced when the table was created.<br>有时只需要扫描表中的一部分数据，因此在创建表时引入了分区概念。</li>
<li>A partitioned table refers to the partition space of the partition specified when the table was created.<br>分区表是指在创建表时指定的分区的分区空间。</li>
<li>To create a partitioned table, you need to use  the optional parameter partitioned by.<br>要创建分区表，需要使用可选的分区参数。</li>
<li>A table can have one or more partitions, and each partition exists in the directory of the table folder in the form of a folder.<br>一个表可以有一个或多个分区，每个分区都以文件夹的形式存在于表文件夹的目录中。</li>
<li>Table and column names are not case sensitive.<br>表名和列名不区分大小写。</li>
<li>Partitions exist in the table structure in the form of fields.<br>分区以字段的形式存在于表结构中。</li>
<li>You can see that the fields  through the <code>describe table</code> command, but this field does not store the actual data , they are only the representation of the partition.<br>你可以通过<code>describe table</code>命令看到这些字段，但是这个字段并不存储实际的数据，它们只是分区的表示。</li>
</ul>
<p>Types of partition table creation   分区表创建的类型</p>
<ul>
<li>Single partition: Which means that there is only one level folder directory under the table folder directory.<br>单分区: 这意味着在表文件夹目录下只有一个级别的文件夹目录。Statement: create table day_table (id int, content string) partitioned by (dt string);</li>
<li>Multi-partitioning: A multi-folder nesting mode appears under the table folder.<br>多分区: 在表文件夹下出现多文件夹嵌套模式。<br>Statement: <code>create table day_hour_table (id int, content string) partitioned by (dt string, hour string);</code></li>
<li>Dual partition table, partitioned by day and hour, added dt and hour two columns in the table structure.<br>双分区表，按日和时进行分区，在表结构中增加了dt和时两列。</li>
<li>Partition table contains Static partition and Dynamic partition<br>分区表包含静态分区和动态分区</li>
</ul>
<p>Static Partition Table</p>
<ul>
<li>It is recommended to create a partitioned column before importing data.<br>建议在导入数据之前创建分区列。</li>
<li>If you do not create the partition first, the partition is created automatically.<br>如果你没有首先创建分区，那么将会自动创建分区。</li>
</ul>
<p>Dynamic Partition Table</p>
<ul>
<li>Dynamic partitioning can be automatically matched to the corresponding partition according to the data obtained by the query.<br>动态分区可以根据查询得到的数据自动匹配到相应的分区。</li>
</ul>
<p>Example :<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> logs_partition_ex </span><br><span class="line">  <span class="keyword">partition</span>(stat_date=<span class="string">'2001-01-02'</span>,province) </span><br><span class="line">  <span class="keyword">select</span> member_id,<span class="keyword">name</span>,province <span class="keyword">from</span> logs_partition</span><br><span class="line">  <span class="keyword">where</span> stat_date=<span class="string">'2001-01-02’;</span></span><br></pre></td></tr></table></figure></p>
<p>stat_date is called a static partition column, and province is called a dynamic partition column.<br>stat_date称为静态分区列，province称为动态分区列<br>In the select clause, dynamic partition columns need to be written in the order of partitioning, while static partition columns need not be written.<br>在select子句中，需要按分区顺序写入动态分区列，而不需要写入静态分区列。<br>In this way, all data with <code>stat_date = &#39;2001-01-02&#39;</code> will be inserted into <code>/user/hive/warehouse/logs_partition/stat_date=2001-01-02/</code> under different subfolders according to the difference of the source.<br>这样，根据来源的不同，所有<code>stat_date = &#39;2001-01-02&#39;</code>的数据将被插入到<code>/user/hive/warehouse/logs_partition/stat_date=2001-01-02/</code>的不同子文件夹中。<br>The province sub-partition corresponding to the data does not exist, it will be automatically created<br>对应的province子分区数据不存在，将会自动创建</p>
<p>Related parameters about dynamic partitioning:   动态分区相关参数:<br><code>hive.exec.dynamic.partition.mode</code>. This value defaults to strict, which means that all columns are not allowed to be dynamic. Set hive.exec .dynamic.partition.mode = nonstrict<br>动态分区允许所有分区的列都是动态分区的列，但是你首先必须设置一个参数<code>hive.exec.dynamic.partition.mode</code>。该值默认为strict，这意味着不允许所有列都是动态的。 <code>hive.exec .dynamic.partition.mode = nonstrict</code><br><code>hive.exec.max.dynamic.partitions.pernode (default value:100)</code>：The maximum number of partitions that each mapreduce job can create. If this number is exceeded, an error will be reported.<br><code>hive.exec.max.dynamic.partitions.pernode</code>:每个mapreduce作业可以创建的最大的分区数。如果超过这个数字，将会报告一个错误。<br><code>hive.exec.max.dynamic.partitions (Default value is 1000)</code>： The maximum number of all partitions allowed in a dml statement.<br><code>hive.exec.max.dynamic.partitions (Default value is 1000)</code>： dml语句中允许的所有分区的最大数。<br><code>hive.exec.max.created.files (The default value is 100,000)</code>: The maximum number of files allowed for all mapreduce jobs.<br><code>hive.exec.max.created.files (The default value is 100,000)</code>:所有mapreduce作业允许的最大文件数。</p>
<h3 id="Bucket-table"><a href="#Bucket-table" class="headerlink" title="Bucket table"></a>Bucket table</h3><ul>
<li>Hive can be further organized into buckets for each table (table or partition).<br>Hive可以进一步的组织到每个表(表或分区)的桶中。</li>
<li>Buckets are more fine-grained data range divisions.<br>桶(Buckets)是更细粒度的数据范围划分。</li>
<li>Hive is also an organization that buckets a certain column.<br>Hive也是一个存储特定列的组织。</li>
<li>Hive determines the bucket in which the record is stored by hashing column values ​​and dividing by the number of buckets.<br>Hive通过散列列值并除以桶(Bucket)的数量来确定存储记录的桶(Buckets) 。</li>
<li>There are two reasons to organize tables (or partitions) into buckets:<br>将表(或分区)组织到桶(Buckets)中有两个原因:<ul>
<li>Get higher query processing efficiency.   获得更高的查询处理效率。 </li>
<li>Buckets add extra structure to the table, which Hive can take advantage of when processing some queries. Specifically, joining two tables that have buckets divided on the same columns (including the joining columns) . 桶(Buckets)为表添加了额外的结构，Hive在处理某些查询时可以利用它。具体来说，连接两个具有相同列上分隔桶(Buckets)的表(包括连接列)。</li>
</ul>
</li>
<li>Make sampling more efficient.    提高采样效率。<br>When dealing with large-scale data sets, if you can test run a small amount of data in the data set during the development and modification of the query, it will bring a lot of convenience.<br>在处理大型数据集时，如果在查询的开发和修改过程中，能够在数据集中测试运行少量的数据，将会带来很大的方便。</li>
</ul>
<p>Bucketing syntax:  Bucketing语法：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> bucketed_user (<span class="keyword">id</span> <span class="built_in">INT</span>, <span class="keyword">name</span> <span class="keyword">STRING</span>)</span><br><span class="line">   CLUSTERED <span class="keyword">BY</span> (<span class="keyword">id</span>) SORTED <span class="keyword">BY</span>(<span class="keyword">id</span>) <span class="keyword">INTO</span> <span class="number">4</span> BUCKETS;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>The CLUSTERED BY clause specifies the columns used to divide the bucket and the number of buckets to be divided.<br>CLUSTERED BY子句指定用于划分桶(Bucket)的列和要划分的桶(Buckets)的数量。</li>
<li>Optional Sorted by clause can be used to sort data inside bucket based on column specified.</li>
<li>Hive uses a hash of the value and divides the result by the number of buckets to get the remainder, which is id.hash ()% 4. The data is put into the bucket based on this result.<br>Hive使用hash值，并将结果除以桶(Buckets )的数量来得到剩余部分，即id.hash()% 4。根据这个结果将数据放入桶(Bucket )中。</li>
<li>To populate the bucket table with data, you need to set the hive.enforce.bucketing property to true. 要用数据填充桶表，你需要设置hive.enforce.bucketing属性设为真。</li>
</ul>
<p>Remember buckets are created in power of 2<br>桶的数量要是2的次方<br>1 bucket = 1 file = 1 reducer<br><code>mapred.reduce.tasks=64</code></p>
<p>Bucket table store data</p>
<ul>
<li>Sometimes partitioning is not suitable in that case create bucket.</li>
<li>Disadvantage of partition<ul>
<li>Partitions can increase as new values are inserted in column.</li>
<li>Partition with small size can degrade the performance.</li>
</ul>
</li>
<li>Advantage of bucket<ul>
<li>The number of buckets is fixed and there is no data fluctuation</li>
<li>The number of Reduces written to the bucket is fixed</li>
</ul>
</li>
</ul>
<h2 id="HQL"><a href="#HQL" class="headerlink" title="HQL"></a>HQL</h2><h3 id="SELECT-Command"><a href="#SELECT-Command" class="headerlink" title="SELECT Command"></a>SELECT Command</h3><p>Syntax<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> [ALL | <span class="keyword">DISTINCT</span>] select_expr, select_expr, ...FROM  table_reference</span><br><span class="line">[<span class="keyword">WHERE</span> where_condition]</span><br><span class="line">[<span class="keyword">GROUP</span> <span class="keyword">BY</span> col_list [<span class="keyword">HAVING</span> condition]]</span><br><span class="line">[CLUSTER <span class="keyword">BY</span> col_list | [<span class="keyword">DISTRIBUTE</span> <span class="keyword">BY</span> col_list] [<span class="keyword">SORT</span> <span class="keyword">BY</span> | <span class="keyword">ORDER</span> <span class="keyword">BY</span> col_list]</span><br><span class="line">] [<span class="keyword">LIMIT</span> <span class="built_in">number</span>]</span><br></pre></td></tr></table></figure></p>
<ul>
<li>We can use <code>ALL</code> option to retrieve all records and <code>DISTINCT</code> options to retrieve all records except duplicate one.<br>我们可以使用ALL选项来检索所有记录，使用DISTINCT选项来检 索除重复记录之外的所有记录。</li>
<li>The default is <code>ALL</code> 默认值是ALL</li>
<li>Where condition is same as SQL and support <code>OR</code> and <code>AND</code> condition<br>Where 条件与SQL相同，支持 OR 和 AND 条件</li>
<li>0.9 version supports <code>BETWEEN</code>, <code>IN</code>, <code>NOT</code> IN but does not support <code>EXIST</code> and <code>NOT EXIST</code><br>0.9版本支持BETWEEN, IN, NOT IN，但不支持 EXIST 和 NOT EXIST</li>
<li><code>ORDER BY</code> clause sort the data globally and there is only one Reduce task<br>ORDER BY子句对数据进行全局排序，并且只有一个Reduce任务</li>
<li><code>SORT BY</code> sorts the data locally<br>SORT BY按本地数据排序</li>
<li>Limit can limit the number of records queried.<br>Limit可以限制查询记录的数量。</li>
<li>We can print the column name By 我们可以用以下打印列名<br><code>set hive.cli.print.header = true;</code></li>
<li>Queries that specify columns using regular expressions<br>使用正则表达式对指定列的查询<br><code>Select id,name,&#39;pv.*&#39; from log</code></li>
<li><code>WHERE</code> clause :  The where condition is a Boolean expression.<br>where条件是一个Boolean表达式</li>
</ul>
<p>Partition-based query   基于分区的查询</p>
<ul>
<li>Normally, a SELECT query scans all tables (except sampling).<br>通常来说，SELECT查询扫描所有表(抽样除外)。</li>
<li>If the table is created with the <code>PARTITIONED BY</code> clause, the query can be partitioned and pruned, and a part of the table is scanned according to the partition range specified by the query.<br>如果使用PARTITIONED BY子句创建表，则可以对查询进行分区和 修剪，并根据查询指定的分区范围扫描表的一部分。</li>
<li>Currently, Hive specifies partitions in the where clause or the ON clause of JOIN and will perform partition trimming.<br>目前，Hive在<code>JOIN</code>的<code>where</code>子句或<code>ON</code>子句中指定分区，并将执行 分区修剪。</li>
</ul>
<p>Limit statement</p>
<ul>
<li>The Limit statement limits the number of rows returned.<br>Limit语句限制返回的行数</li>
<li>Example : <code>select * from pv limit 3;</code></li>
</ul>
<p>Column alias   (列别名)</p>
<ul>
<li>Example : select userid as uid from pv; </li>
</ul>
<p>Nested select    (嵌套的选择)</p>
<ul>
<li>Hive statements support nested select statements.<br>Hive语句支持nested select语句</li>
</ul>
<p>Like and RLike</p>
<ul>
<li>Like is a standard SQL statement, and RLike is an extension of Hive. You can specify matching conditions through java regular expressions.<br>Like是一个标准的SQL语句，而RLike是Hive的扩展。可以通过java 正则表达式for指定匹配条件<br>Example:<br><code>Select name,address.street from employees where address.street RLIKE &#39;.*(A|B).*&#39;</code><br><code>Select name,address.street from employees where address.street LIKE &#39;R%&#39;</code></li>
</ul>
<p>Group by </p>
<ul>
<li>Group by is used with aggregate functions (avg, sum, min, max, count) to group results by one or more columns:<br>Group by与聚集函数一起使用，将结果按一个或多个列分组:<br>Example : <code>Select count(id) from t_pv group by id;</code></li>
</ul>
<p>HAVING clause<br><code>SELECT col1 FROM t1 GROUP BY col1 HAVING SUM(col2) &gt; 10</code><br><code>SELECT col1 FROM (SELECT col1, SUM(col2) AS col2sum FROM t1 GROUP BY col1) t2 WHERE t2.col2sum &gt; 1</code><br>(Both queries will give same output) （两个查询将给出相同的输出）</p>
<h3 id="Join-statement"><a href="#Join-statement" class="headerlink" title="Join statement"></a>Join statement</h3><p>支持 INNER JOIN, FULL JOIN, LEFT JOIN, RIGHT JOIN</p>
<p>Syntax<br>join_table:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">table_reference JOIN table_factor [join_condition] </span><br><span class="line">| table_reference &#123;LEFT|RIGHT|FULL&#125; [OUTER] JOIN table_reference join_condition</span><br><span class="line">| table_reference LEFT SEMI JOIN table_reference join_condition</span><br></pre></td></tr></table></figure></p>
<p>table_reference:<br>    table_factor   | join_table<br>table_factor:<br>    tbl_name [alias]   | table_subquery alias   | ( table_references )<br>join_condition:<br>    ON equality_expression_r( AND equality_expression )* equality_expression:<br>    expression = expression</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>NIIT</li>
</ul>

    </div>

    
    
    
        <div class="reward-container">
  <div>Have fun.</div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    Donate
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/blog/images/wechatpay.png" alt="BeiYu WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/blog/images/alipay.png" alt="BeiYu Alipay">
        <p>Alipay</p>
      </div>

  </div>
</div>

        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:  </strong>BeiYu
  </li>
  <li class="post-copyright-link">
    <strong>Post link: </strong>
    <a href="/blog/beiyuouo.github.io/blog/note-hive/" title="Hive笔记">beiyuouo.github.io/blog/note-hive/</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/en" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> unless stating additionally.
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/blog/tags/note/" rel="tag"># note</a>
              <a href="/blog/tags/hive/" rel="tag"># hive</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/problem-pta/" rel="prev" title="PTA部分题解">
      <i class="fa fa-chevron-left"></i> PTA部分题解
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/problem-kickstart-2020-round-A/" rel="next" title="KickStart2020 Round A">
      KickStart2020 Round A <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-to-Hive"><span class="nav-number">1.</span> <span class="nav-text">Introduction to Hive</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Difference-between-SQL-and-NoSQL"><span class="nav-number">1.1.</span> <span class="nav-text">Difference between SQL and NoSQL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-Hive"><span class="nav-number">1.2.</span> <span class="nav-text">What is Hive</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Who-developed-Hive"><span class="nav-number">1.3.</span> <span class="nav-text">Who developed Hive</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Why-Hive-was-developed"><span class="nav-number">1.4.</span> <span class="nav-text">Why Hive was developed?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-and-when-it-can-be-used"><span class="nav-number">1.5.</span> <span class="nav-text">How and when it can be used?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#When-Hive-cannot-be-used"><span class="nav-number">1.6.</span> <span class="nav-text">When Hive cannot be used?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Features-of-Hive"><span class="nav-number">1.7.</span> <span class="nav-text">Features of Hive</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Difference-between-Hive-amp-RDBMS"><span class="nav-number">1.8.</span> <span class="nav-text">Difference between Hive &amp; RDBMS</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hive-Chapter-1"><span class="nav-number">2.</span> <span class="nav-text">Hive Chapter 1</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#What-is-Hive-1"><span class="nav-number">2.1.</span> <span class="nav-text">What is Hive?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#How-to-analyze-and-manage-data-如何分析和管理数据"><span class="nav-number">2.2.</span> <span class="nav-text">How to analyze and manage data? 如何分析和管理数据?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIVE-Data-Storage-Model-HIVE数据存储模型"><span class="nav-number">2.3.</span> <span class="nav-text">HIVE Data Storage Model.  HIVE数据存储模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIVE-Data-Storage-Hive数据存储"><span class="nav-number">2.4.</span> <span class="nav-text">HIVE Data Storage. Hive数据存储</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Data-Models-Table-Hive-数据模型-Table"><span class="nav-number">2.5.</span> <span class="nav-text">Hive Data Models-Table. Hive 数据模型-Table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Data-Models-External-Table-Hive-数据模型"><span class="nav-number">2.6.</span> <span class="nav-text">Hive Data Models-External Table. Hive 数据模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Data-Models-Partition-Hive-数据模型-Partition"><span class="nav-number">2.7.</span> <span class="nav-text">Hive Data Models-Partition. Hive 数据模型-Partition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Data-Models-Bucket-Hive-数据模型-Bucket"><span class="nav-number">2.8.</span> <span class="nav-text">Hive Data Models-Bucket. Hive 数据模型-Bucket</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-MetaData"><span class="nav-number">2.9.</span> <span class="nav-text">Hive MetaData</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Storage-model"><span class="nav-number">2.10.</span> <span class="nav-text">Hive Storage model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Database-Model"><span class="nav-number">2.11.</span> <span class="nav-text">Database Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Installation"><span class="nav-number">2.12.</span> <span class="nav-text">Hive Installation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#基于Derby"><span class="nav-number">2.12.1.</span> <span class="nav-text">基于Derby</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基于Mysql"><span class="nav-number">2.12.2.</span> <span class="nav-text">基于Mysql</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CLI-Options"><span class="nav-number">2.13.</span> <span class="nav-text">CLI Options</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Variable-setting"><span class="nav-number">2.14.</span> <span class="nav-text">Variable setting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hive-Command-line"><span class="nav-number">2.15.</span> <span class="nav-text">Hive Command line</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIVE-Data-Type"><span class="nav-number">2.16.</span> <span class="nav-text">HIVE Data Type</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chapter-2"><span class="nav-number">3.</span> <span class="nav-text">Chapter 2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Database-Operations"><span class="nav-number">3.1.</span> <span class="nav-text">Database Operations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Table-Operations"><span class="nav-number">3.2.</span> <span class="nav-text">Table Operations</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#File-formats"><span class="nav-number">3.2.1.</span> <span class="nav-text">File formats</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CREATE-TABLE"><span class="nav-number">3.2.2.</span> <span class="nav-text">CREATE TABLE</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Modify-Table-Operations"><span class="nav-number">3.3.</span> <span class="nav-text">Modify Table Operations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Table-Operations-1"><span class="nav-number">3.4.</span> <span class="nav-text">Table Operations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-loading"><span class="nav-number">3.5.</span> <span class="nav-text">Data loading</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Ways-to-Import-data-in-batches"><span class="nav-number">3.6.</span> <span class="nav-text">Ways to Import data in batches</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Management-tables"><span class="nav-number">3.7.</span> <span class="nav-text">Management tables</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#External-tables"><span class="nav-number">3.8.</span> <span class="nav-text">External tables</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Partition-Table"><span class="nav-number">3.9.</span> <span class="nav-text">Partition Table</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bucket-table"><span class="nav-number">3.10.</span> <span class="nav-text">Bucket table</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HQL"><span class="nav-number">4.</span> <span class="nav-text">HQL</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#SELECT-Command"><span class="nav-number">4.1.</span> <span class="nav-text">SELECT Command</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Join-statement"><span class="nav-number">4.2.</span> <span class="nav-text">Join statement</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">5.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="BeiYu"
      src="/blog/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">BeiYu</p>
  <div class="site-description" itemprop="description">Sometimes it's the very people who no one imagines angthing of who do the things that no one can imagine.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives/">
        
          <span class="site-state-item-count">112</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/blog/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/blog/tags/">
        <span class="site-state-item-count">88</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/beiyuouo" title="GitHub → https://github.com/beiyuouo" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:bj.yan.pa@qq.com" title="E-Mail → mailto:bj.yan.pa@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/5687969852" title="Weibo → https://weibo.com/u/5687969852" rel="noopener" target="_blank"><i class="fa fa-fw fa-weibo"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="http://wpa.qq.com/msgrd?v=3&uin=729320011&site=qq&menu=yes" title="QQ → http://wpa.qq.com/msgrd?v=3&uin=729320011&site=qq&menu=yes" rel="noopener" target="_blank"><i class="fa fa-fw fa-qq"></i>QQ</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/bei-yu-84-25/activities" title="ZhiHu → https://www.zhihu.com/people/bei-yu-84-25/activities" rel="noopener" target="_blank"><i class="fa fa-fw fa-unlink"></i>ZhiHu</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/en" class="cc-opacity" rel="noopener" target="_blank"><img src="/blog/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="/blog/" title="/">欢迎友链qwq</a>
        </li>
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">BeiYu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>
  <script src="/blog/lib/velocity/velocity.min.js"></script>
  <script src="/blog/lib/velocity/velocity.ui.min.js"></script>
<script src="/blog/js/utils.js"></script><script src="/blog/js/motion.js"></script>
<script src="/blog/js/schemes/pisces.js"></script>
<script src="/blog/js/next-boot.js"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>




  <script src="/blog/js/local-search.js"></script>












  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'jbPOrMNQ1tKOuqaj5INbG6Xx-gzGzoHsz',
      appKey     : '3IKT41wJqXOlVHOHgahLKltR',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
